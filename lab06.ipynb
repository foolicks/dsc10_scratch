{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iojQcQiRaKY"
      },
      "source": [
        "# Lab 6: Hypothesis Testing\n",
        "\n",
        "## Due Thursday, May 23rd at 11:59PM\n",
        "\n",
        "Welcome to Lab 6! In this assignment, we'll develop a further understanding of hypothesis testing, which you can learn more about in [CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html). The relevant lectures are Lectures 19, 20, and 21.\n",
        "\n",
        "You should complete this entire lab so that all tests pass and submit it to Gradescope by 11:59PM on the due date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "xFfRutYWRaKb",
        "outputId": "19c503f6-6fd1-46b1-dbd0-f1981be4ff40"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'babypandas'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03629acde4d4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbabypandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'babypandas'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import babypandas as bpd\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "\n",
        "import otter\n",
        "grader = otter.Notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXf6Ngn0RaKc"
      },
      "source": [
        "## 1. Therapeutic Touch 👆"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install babypandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "f_Z7yl4mRgcz",
        "outputId": "68eb2d3f-7aa3-4bca-f236-0216f1606497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting babypandas\n",
            "  Downloading babypandas-0.1.9-py3-none-any.whl (15 kB)\n",
            "Collecting pandas<=1.5.3,>=0.24 (from babypandas)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from babypandas) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.5.3,>=0.24->babypandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.5.3,>=0.24->babypandas) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<=1.5.3,>=0.24->babypandas) (1.16.0)\n",
            "Installing collected packages: pandas, babypandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed babypandas-0.1.9 pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "58def0c588444e8fa94fbb264e4f40d0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78rIRSOMRaKd"
      },
      "source": [
        "Therapeutic Touch (TT) is an energy therapy that practitioners claim can promote health and relaxation. Practitioners place their hands near a patient and say they are able to detect and manipulate the patient's so-called Human Energy Field (HEF).\n",
        "TT was popular throughout the 20th century and was touted as a great way to bring balance to a person's health. You can [read more about TT here](https://www.mountsinai.org/health-library/treatment/therapeutic-touch).\n",
        "\n",
        "### Emily Rosa's Experiment\n",
        "\n",
        "In 1996, Emily Rosa was a 9 year old who had wide exposure to the world of TT due to her parents, who were both medical practitioners and skeptics of the idea of TT. For her 4th grade science fair project, Emily decided to test whether or not TT practitioners could truly interact with a person's HEF.\n",
        "\n",
        "Emily's experiment was clean, simple, and effective. Due to her parents' occupations in the medical field, she had easy access to TT practitioners. With each practitioner, she performed the following experiment several times over several days.\n",
        "\n",
        "1. First, she would separate herself from the practitioner with a board, so they couldn't see each other.\n",
        "1. Then she'd ask them to place both of their hands through an opening in the board.\n",
        "1. Emily would flip a fair coin to randomly determine whether to place her hands near the practitioner's left hand or right hand.\n",
        "1. Finally, Emily would ask the TT practitioner to specify whether they could detect Emily's Human Energy Field (HEF) near their left hand or their right hand.\n",
        "\n",
        "Overall, Emily performed 280 experiments, and the practitioner picked the correct hand 123 times.\n",
        "\n",
        "Emily's main goal here was to test whether or not the TT practitioners' guesses were random, like the flip of a coin. In most medical experiments, this is the norm. We want to test whether or not some treatment has an effect. This is *not* the same as testing whether the treatment actually works as intended.\n",
        "\n",
        "We will now begin to formulate Emily's experiment in terms of the hypothesis terminology we've learned recently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BRTxkKzPRaKe"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question 1.1.** What are the null and alternative hypotheses for Emily's experiment? Write both of your answers in the cell below.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_1\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7wAhYloRaKe"
      },
      "source": [
        "<h1> the null is the coin see Q1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Roh5SSCRaKf"
      },
      "source": [
        "The null hypothesis is that the practioners were able to detect the HEF more so than the chances of a flipping a coin. The alternative is that they fail to prove [are able to detect the HEF] with statistical significance they can predict more frequently than the coin flip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhYbnN7NRaKf"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "**Question 1.2.** Remember that in 280 experiments, the practitioner guessed the correct hand 123 times. According to the null hypothesis, on average, what proportion of times do we expect the practitioner to guess the correct hand? Make sure your answer is between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXw2BRzqRaKg",
        "outputId": "df6d86a1-5bf7-47c4-af25-380f4242a953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "expected_correct = .5\n",
        "expected_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0lQ09seGRaKh",
        "outputId": "014033a3-5499-483c-e3ec-305fe7d0ddab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p><strong><pre style='display: inline;'>q1_2</pre></strong> passed!</p>"
            ],
            "text/plain": [
              "q1_2 results: All test cases passed!"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grader.check(\"q1_2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ1Tvve-RaKi"
      },
      "source": [
        "The goal now is to see if our deviation from this expected proportion of correct answers is due to something other than chance.\n",
        "\n",
        "**Question 1.3.** Which of the following is the best statistic for testing this model? Assign `best_stat` to 1, 2, or 3.\n",
        "\n",
        "1. The difference between the expected proportion of correct answers and the actual proportion of correct answers.\n",
        "2. The absolute difference between the expected proportion of correct answers and the actual proportion of correct answers.\n",
        "3. The sum of the expected proportion of correct answers and the actual proportion of  correct answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxGkSuiHRaKj"
      },
      "outputs": [],
      "source": [
        "best_stat = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LBgjfSGiRaKj",
        "outputId": "cf6cac2a-eee1-42c8-ab68-1ade3c69fa38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p><strong><pre style='display: inline;'>q1_3</pre></strong> passed!</p>"
            ],
            "text/plain": [
              "q1_3 results: All test cases passed!"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grader.check(\"q1_3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkvFlVpMRaKk"
      },
      "source": [
        "***Note:*** If you initially answered 1.3 incorrectly, take some time to review the [coin flipping example in Lecture 20](https://dsc10.com/resources/lectures/lec20/lec20.html#Example:-Is-our-coin-fair?) before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhoSxbXDRaKk"
      },
      "source": [
        "**Question 1.4.** Complete the implementation of the function `calculate_test_stat`, which takes in an expected proportion and an actual proportion and returns the value of the test statistic you chose (as a proportion between 0 and 1). Assume that both inputs are proportions between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-Dl9wb_RqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaHZHxssRaKl"
      },
      "outputs": [],
      "source": [
        "def calculate_test_stat(expected_prop, actual_prop):\n",
        "    return abs(expected_prop - actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4hiaaunqRaKl"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0brs0AfRaKl"
      },
      "source": [
        "**Question 1.5.** Use your newly defined function to calculate the observed test statistic for Emily's experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSPve9UBRaKm",
        "outputId": "1043d3b7-018d-4d7d-cf6d-6a5ad2e1f237"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'calculate_test_stat' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_113/3048638708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobserved_test_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_test_stat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobserved_test_stat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'calculate_test_stat' is not defined"
          ]
        }
      ],
      "source": [
        "observed_test_stat = calculate_test_stat(.5,123/280)\n",
        "observed_test_stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tt9gzhm8RaKm"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_dr5ZN7RaKn"
      },
      "source": [
        "**Is this test statistic likely if the null hypothesis is true? Or is the deviation from the expected proportion due to something other than chance?**\n",
        "\n",
        "In order to answer this question, we need to see how our test statistic would come out if the null hypothesis were true, to see if our observed test statistic is similar. Therefore, we will simulate Emily's experiment assuming that the null hypothesis is true, and calculate the test statistic for each simulation.\n",
        "\n",
        "**Question 1.6.** To begin simulating, start by creating an array which has two items in it. The first item should be the proportion of times, assuming the null hypothesis is true, a TT practitioner detects Emily's HEF correctly. The second item should be the proportion of times, under the same assumption, that the TT practitioner makes an incorrect guess. Assign `model_proportions` to this array.\n",
        "\n",
        "After this, use the `np.random.multinomial` function to simulate Emily repeating her experiment 280 times (the same nuber of experiments she did in real life), and assign the proportion of correct guesses to `simulation_proportion`. Lastly, define `one_simulated_test_stat` to be the test statistic of this one simulation.\n",
        "\n",
        "***Hint:*** See Lecture 19 or [the documentation for `np.random.multinomial`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html) for guidance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNxpsyCQRaKn"
      },
      "outputs": [],
      "source": [
        "model_proportions = [.5,]\n",
        "simulation_proportion = np.random.multinomial(280,model_proportions)\n",
        "one_simulated_test_stat = ...\n",
        "one_simulated_test_stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kz3b4Vz1RaKo"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMoDLePCRaKo"
      },
      "source": [
        "**Question 1.7.** Let's now see what the distribution of test statistics is actually like under our null hypothesis. Assign `simulated_test_stats` to an array of 10,000 test statistics that you simulate, under the assumption that the null hypothesis is true.\n",
        "\n",
        "***Hint:*** You'll need to re-use most of the code you wrote in 1.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "for_assignment_type": "student",
        "scrolled": true,
        "id": "r7ueFc06RaKo"
      },
      "outputs": [],
      "source": [
        "num_repetitions = ...\n",
        "simulated_test_stats = []\n",
        "test_stats = []\n",
        "  for _ in range(num_samples):\n",
        "    sample = np.random.binomial(100, expected_prop)\n",
        "    actual_prop = sample.mean()\n",
        "    test_stat = abs(expected_prop - actual_prop)\n",
        "    test_stats.append(test_stat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4PX0ibt1RaKp"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzvaCrgQRaKp"
      },
      "source": [
        "Let's view the distribution of the simulated test statistics under the null, to see how the observed test statistic compares to the simulated ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgAZMchmRaKp"
      },
      "outputs": [],
      "source": [
        "t = bpd.DataFrame().assign(Simulated_Test_Statistics=simulated_test_stats)\n",
        "t.plot(kind='hist', density=True, ec='w', bins=np.arange(0, 0.15, 0.005), figsize=(10, 5))\n",
        "plt.axvline(x=observed_test_stat, color='black', label='observed statistic', linewidth=4)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuyxe96qRaKq"
      },
      "source": [
        "We can make a visual argument as to whether or not we believe the observed test statistic is likely to occur under the null, or we can use the definition of p-values to help us make a more formal argument.\n",
        "\n",
        "**Question 1.8.** First, let's remember what a p-value is. Assign `p_def` to the integer corresponding to the correct definition of a p-value.\n",
        "\n",
        "1. The chance, under the null hypothesis, that the test statistic is equal to the value that was observed.\n",
        "2. The chance, under the null hypothesis, that the test statistic is equal to the value that was observed or is even further in the direction of the alternative.\n",
        "3. The chance, under the alternative hypothesis, that the test statistic is equal to the value that was observed or is even further in the direction of the null.\n",
        "4. The number of times, under the null hypothesis, that the test statistic is equal to the value that was observed or is even further in the direction of the alternative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEzVmzEQRaKq"
      },
      "outputs": [],
      "source": [
        "p_def = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c03ScDMcRaKq"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ugaW6-RaKr"
      },
      "source": [
        "**Question 1.9.** Using the definition above, calculate the p-value for Emily's experiment and assign it to `emily_p_val`.\n",
        "\n",
        "***Hint:*** Do large values of our test statistic make you lean towards the null or alternative? Refer to Lecture 21 or [CIT 11.1](https://inferentialthinking.com/chapters/11/1/Assessing_a_Model.html) for examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9QCagDnRaKr"
      },
      "outputs": [],
      "source": [
        "emily_p_val = ...\n",
        "emily_p_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GMRpMmUBRaKs"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1_9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpuCqu1iRaKs"
      },
      "source": [
        "Since we want to be very sure about the effectiveness of medical treatments, let's use a significance level of 0.01, the standard convention for being \"highly statistically significant.\" This means that if our p-value is less than or equal to 0.01, then we reject the null hypothesis in favor of the alternative. Otherwise, we fail to reject the null hypothesis. **Note that this does not mean we accept the null hypothesis as correct, but rather, that we don't have enough evidence to reject it.**\n",
        "\n",
        "Your p-value and this convention should help you make your own conclusions about Emily Rosa's experiment.\n",
        "\n",
        "Therapeutic Touch fell out of use after this experiment, which was eventually [accepted into a premier medical journal](https://pubmed.ncbi.nlm.nih.gov/9533499/). TT practitioners hit back and accused Emily and her family of tampering with the results, while some claimed that Emily's bad spiritual mood towards Therapeutic Touch made it difficult to read her HEF. Whatever it may be, Emily's experiment is a classic example about how anyone, with the right resources, can test anything they want!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbvofBZHRaKt"
      },
      "source": [
        "## 2. YouTube Advertisements ▶️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Th6EJ2RaKt"
      },
      "source": [
        "YouTube, the world's largest video sharing platform, generates revenue from advertisements that appear before and during videos.\n",
        "\n",
        "Suppose that YouTube publicly released a statement revealing that 94% of their advertisements are skippable (meaning that, supposedly, only 6% of their advertisements cannot be skipped).\n",
        "\n",
        "King Triton, UCSD's trusty mascot, wanted to test if this claim was accurate. He clicked on several videos, and recorded whether or not the advertisements on each video were skippable. He watched videos until he reached 100 advertisements, and found that 16 of them were unskippable, or only 84% were skippable. King Triton is irritated and believes that YouTube's claim of 94% is too high. Let's investigate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-fMg46DqRaKu"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question 2.1.** You decide to run a hypothesis test. What are the null and alternative hypotheses for your test? Write both answers in the cell below.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q2_1\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faJfMIvmRaKu"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3DRVIkHRaKu"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "**Question 2.2.** Assign `null_probabilities` to a two-item *array* such that the **first** element is the chance that a YouTube advertisement is **skippable**, and the **second** element is the chance that a YouTube advertisement is **unskippable**, under the assumptions of the **null hypothesis**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBzJEfozRaKv"
      },
      "outputs": [],
      "source": [
        "null_probabilities = ...\n",
        "null_probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "X8f9MOCFRaKv"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q2_2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByxcvWfBRaKw"
      },
      "source": [
        "**Question 2.3.** Using the array you defined above, simulate the act of watching 100 YouTube advertisements, 10,000 times. Create an array called `unskippable_counts` containing the **number of unskippable advertisements** in each simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wu98cE5RaKw"
      },
      "outputs": [],
      "source": [
        "unskippable_counts = ...\n",
        "unskippable_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HTBrAvYhRaKx"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q2_3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckxY5PGtRaKx"
      },
      "source": [
        "Run the cell below to visualize the results of the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IspKjF_WRaKy"
      },
      "outputs": [],
      "source": [
        "bpd.DataFrame().assign(unskippable_counts = unskippable_counts) \\\n",
        "               .plot(kind='hist', density=True, bins=np.arange(20), ec='w', figsize=(10, 5))\n",
        "plt.axvline(x=16, color='black', label='observed statistic', linewidth=4)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTwEjQ_xRaKy"
      },
      "source": [
        "**Question 2.4.** Use the results of the simulation to calculate the p-value for this hypothesis test and assign your answer to `unskippable_p_val`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCebH1AKRaKz"
      },
      "outputs": [],
      "source": [
        "unskippable_p_val = ...\n",
        "unskippable_p_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "47RUSn-YRaKz"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q2_4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdQ9z4ZBRaK0"
      },
      "source": [
        "You should be able to tell, both from the histogram and from the p-value you calculated, that YouTube seems to have more unskippable advertisements than they claim! Perhaps they had a typo in their announcement and meant to say 84% instead of 94%?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV2ou0QIRaK0"
      },
      "source": [
        "## Finish Line 🏁\n",
        "\n",
        "Congratulations! You are done with Lab 6.\n",
        "\n",
        "**Citations:** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqpG8IvBRaK0"
      },
      "source": [
        "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
        "\n",
        "Please cite tools here.\n",
        "\n",
        "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz8MT0s1RaK1"
      },
      "source": [
        "To submit your assignment:\n",
        "\n",
        "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
        "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
        "3. Run the cell below to run all tests, and make sure that they all pass.\n",
        "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
        "5. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
        "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "UgJ1zPMgRaK1"
      },
      "outputs": [],
      "source": [
        "# For your convenience, you can run this cell to run all the tests at once!\n",
        "grader.check_all()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}